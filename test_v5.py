#!/usr/bin/env python3
# test_v5.py - Context Scraper V5 åŸºç¡€æµ‹è¯•

import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from server_v5_core import (
    V5LayeredEngine,
    V5IntentAnalyzer, 
    ResearchMode,
    ExecutionStage
)

async def test_v5_core():
    """æµ‹è¯•V5æ ¸å¿ƒç»„ä»¶"""
    print("ğŸ§ª å¼€å§‹V5æ ¸å¿ƒç»„ä»¶æµ‹è¯•")
    
    # æµ‹è¯•æ„å›¾åˆ†æå™¨
    print("\n1ï¸âƒ£ æµ‹è¯•æ„å›¾åˆ†æå™¨...")
    analyzer = V5IntentAnalyzer()
    
    test_cases = [
        ("å¿«é€Ÿäº†è§£ç‰¹æ–¯æ‹‰çš„è‡ªåŠ¨é©¾é©¶æŠ€æœ¯", ["https://tesla.com"]),
        ("æ·±å…¥åˆ†æOpenAIå’ŒAnthropicçš„ç«äº‰ç­–ç•¥", ["https://openai.com", "https://anthropic.com"]),
        ("å¯¹æ¯”ä¸‰å®¶AIå…¬å¸çš„äº§å“", ["https://openai.com", "https://anthropic.com", "https://google.com"])
    ]
    
    for query, websites in test_cases:
        context = analyzer.analyze_research_intent(query, websites)
        print(f"   æŸ¥è¯¢: {query}")
        print(f"   æ¨¡å¼: {context.mode.value}")
        print(f"   é¢„ä¼°æ—¶é—´: {context.estimated_time}ç§’")
        print(f"   éœ€è¦æ·±åº¦çˆ¬å–: {context.needs_deep_crawl}")
        print(f"   ç«äº‰åˆ†æ: {context.competitive_analysis}")
        print()
    
    # æµ‹è¯•åˆ†å±‚å¼•æ“
    print("2ï¸âƒ£ æµ‹è¯•åˆ†å±‚å¼•æ“...")
    engine = V5LayeredEngine()
    
    def progress_callback(progress_info):
        print(f"   è¿›åº¦: {progress_info.stage.value} ({progress_info.progress:.1f}%) - {progress_info.message}")
    
    try:
        result = await engine.execute_research(
            query="æµ‹è¯•æŸ¥è¯¢",
            websites="https://example.com",
            mode="quick",
            progress_callback=progress_callback
        )
        
        print(f"   âœ… åˆ†å±‚å¼•æ“æµ‹è¯•æˆåŠŸ")
        print(f"   æ‰§è¡Œæ¨¡å¼: {result['context'].mode.value}")
        print(f"   Layer1ç»“æœ: {result['layer1_result']['websites_crawled']} ä¸ªç½‘ç«™")
        print(f"   Layer2ç½®ä¿¡åº¦: {result['layer2_result']['confidence']}")
        
    except Exception as e:
        print(f"   âŒ åˆ†å±‚å¼•æ“æµ‹è¯•å¤±è´¥: {str(e)}")
    
    print("\nâœ… V5æ ¸å¿ƒç»„ä»¶æµ‹è¯•å®Œæˆ")

async def test_v5_modes():
    """æµ‹è¯•V5ä¸åŒæ¨¡å¼"""
    print("\nğŸ¯ æµ‹è¯•V5ä¸åŒç ”ç©¶æ¨¡å¼")
    
    analyzer = V5IntentAnalyzer()
    
    mode_tests = [
        ("å¿«é€Ÿçœ‹çœ‹è¿™ä¸ªå…¬å¸", ResearchMode.QUICK),
        ("è¯¦ç»†åˆ†æå¸‚åœºè¶‹åŠ¿", ResearchMode.STANDARD), 
        ("æ·±å…¥ç ”ç©¶æŠ€æœ¯æ¶æ„", ResearchMode.DEEP),
        ("å¯¹æ¯”ç«äº‰å¯¹æ‰‹äº§å“", ResearchMode.STANDARD)
    ]
    
    for query, expected_mode in mode_tests:
        context = analyzer.analyze_research_intent(query, ["https://example.com"])
        result = "âœ…" if context.mode == expected_mode else "âŒ"
        print(f"   {result} '{query}' -> {context.mode.value} (æœŸæœ›: {expected_mode.value})")

def test_v5_imports():
    """æµ‹è¯•V5å¯¼å…¥"""
    print("ğŸ“¦ æµ‹è¯•V5æ¨¡å—å¯¼å…¥")
    
    try:
        from server_v5_core import V5LayeredEngine
        print("   âœ… V5LayeredEngine å¯¼å…¥æˆåŠŸ")
        
        from server_v5_core import V5ProgressTracker
        print("   âœ… V5ProgressTracker å¯¼å…¥æˆåŠŸ")
        
        from server_v5_core import ResearchMode, ExecutionStage
        print("   âœ… æšä¸¾ç±»å‹å¯¼å…¥æˆåŠŸ")
        
        print("   ğŸ“Š å¯ç”¨ç ”ç©¶æ¨¡å¼:", [mode.value for mode in ResearchMode])
        print("   ğŸ“Š æ‰§è¡Œé˜¶æ®µ:", [stage.value for stage in ExecutionStage])
        
    except ImportError as e:
        print(f"   âŒ å¯¼å…¥å¤±è´¥: {str(e)}")

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ Context Scraper V5 æµ‹è¯•å¼€å§‹")
    print("=" * 50)
    
    # åŸºç¡€å¯¼å…¥æµ‹è¯•
    test_v5_imports()
    
    # æ ¸å¿ƒç»„ä»¶æµ‹è¯•
    await test_v5_core()
    
    # æ¨¡å¼æµ‹è¯•
    await test_v5_modes()
    
    print("\n" + "=" * 50)
    print("ğŸ‰ V5æµ‹è¯•å®Œæˆï¼")
    
    # ç®€å•æ€§èƒ½åŸºå‡†
    print("\nâ±ï¸ ç®€å•æ€§èƒ½åŸºå‡†:")
    import time
    
    start_time = time.time()
    analyzer = V5IntentAnalyzer()
    for i in range(100):
        context = analyzer.analyze_research_intent(f"æµ‹è¯•æŸ¥è¯¢{i}", ["https://example.com"])
    
    elapsed = time.time() - start_time
    print(f"   æ„å›¾åˆ†æ 100æ¬¡: {elapsed:.3f}ç§’ (å¹³å‡ {elapsed*10:.1f}ms/æ¬¡)")

if __name__ == "__main__":
    asyncio.run(main())
