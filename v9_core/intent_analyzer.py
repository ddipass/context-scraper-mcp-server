# v9_core/intent_analyzer.py - V9 æ— åè§æ„å›¾åˆ†æå™¨
import re
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from enum import Enum

class IntentType(Enum):
    """æ„å›¾ç±»å‹"""
    SEARCH = "search"           # æœç´¢è¯·æ±‚
    CRAWL = "crawl"            # çˆ¬å–è¯·æ±‚  
    RESEARCH = "research"       # ç ”ç©¶åˆ†æ
    EXTRACT = "extract"         # æ•°æ®æå–
    MONITOR = "monitor"         # ç›‘æ§ä»»åŠ¡
    COMPARE = "compare"         # å¯¹æ¯”åˆ†æ

class SearchEngineIntent(Enum):
    """æœç´¢å¼•æ“æ„å›¾"""
    EXPLICIT = "explicit"       # æ˜ç¡®æŒ‡å®š
    IMPLICIT = "implicit"       # éšå«åå¥½
    AUTO = "auto"              # è‡ªåŠ¨é€‰æ‹©

@dataclass
class UserIntent:
    """ç”¨æˆ·æ„å›¾åˆ†æç»“æœ"""
    # ä¸»è¦æ„å›¾
    primary_intent: IntentType
    confidence: float
    
    # æœç´¢å¼•æ“ç›¸å…³
    search_engine: Optional[str] = None
    search_engine_intent: SearchEngineIntent = SearchEngineIntent.AUTO
    search_keywords: List[str] = None
    
    # å†…å®¹ç±»å‹
    content_type: Optional[str] = None
    language_preference: Optional[str] = None
    
    # ç‰¹æ®Šéœ€æ±‚
    stealth_required: bool = False
    dynamic_content: bool = False
    batch_processing: bool = False
    
    # åŸå§‹è¾“å…¥
    raw_input: str = ""
    processed_tokens: List[str] = None

class V6IntentAnalyzer:
    """V9 æ— åè§æ„å›¾åˆ†æå™¨"""
    
    def __init__(self):
        # æœç´¢å¼•æ“å…³é”®è¯æ˜ å°„ (æ”¯æŒå¤šè¯­è¨€)
        self.search_engine_keywords = {
            "google": [
                "google", "è°·æ­Œ", "Google", "GOOGLE",
                "ç”¨google", "ç”¨è°·æ­Œ", "googleæœç´¢", "è°·æ­Œæœç´¢",
                "åœ¨google", "åœ¨è°·æ­Œ", "é€šè¿‡google", "é€šè¿‡è°·æ­Œ"
            ],
            "baidu": [
                "baidu", "ç™¾åº¦", "Baidu", "BAIDU", 
                "ç”¨ç™¾åº¦", "ç™¾åº¦æœç´¢", "åœ¨ç™¾åº¦", "é€šè¿‡ç™¾åº¦",
                "ç”¨baidu", "baiduæœç´¢", "åœ¨baidu", "é€šè¿‡baidu"
            ],
            "bing": [
                "bing", "å¿…åº”", "Bing", "BING",
                "ç”¨bing", "ç”¨å¿…åº”", "bingæœç´¢", "å¿…åº”æœç´¢",
                "åœ¨bing", "åœ¨å¿…åº”", "é€šè¿‡bing", "é€šè¿‡å¿…åº”"
            ],
            "yahoo": [
                "yahoo", "é›…è™", "Yahoo", "YAHOO",
                "ç”¨yahoo", "ç”¨é›…è™", "yahooæœç´¢", "é›…è™æœç´¢",
                "åœ¨yahoo", "åœ¨é›…è™", "é€šè¿‡yahoo", "é€šè¿‡é›…è™"
            ],
            "duckduckgo": [
                "duckduckgo", "duck", "ddg", "DuckDuckGo",
                "ç”¨duckduckgo", "duckduckgoæœç´¢", "ç”¨ddg", "ddgæœç´¢"
            ]
        }
        
        # æ„å›¾å…³é”®è¯
        self.intent_keywords = {
            IntentType.SEARCH: [
                "æœç´¢", "æŸ¥æ‰¾", "æ‰¾", "search", "find", "look for",
                "æœä¸€ä¸‹", "æŸ¥ä¸€ä¸‹", "æ‰¾ä¸€ä¸‹", "æœæœ", "æŸ¥æŸ¥"
            ],
            IntentType.CRAWL: [
                "çˆ¬å–", "æŠ“å–", "è·å–", "crawl", "scrape", "fetch",
                "çˆ¬ä¸€ä¸‹", "æŠ“ä¸€ä¸‹", "å–ä¸€ä¸‹", "çˆ¬", "æŠ“"
            ],
            IntentType.RESEARCH: [
                "ç ”ç©¶", "åˆ†æ", "è°ƒç ”", "research", "analyze", "study",
                "æ·±å…¥äº†è§£", "è¯¦ç»†åˆ†æ", "å…¨é¢ç ”ç©¶", "è°ƒæŸ¥"
            ],
            IntentType.EXTRACT: [
                "æå–", "å¯¼å‡º", "æ•´ç†", "extract", "export", "organize",
                "æå–æ•°æ®", "å¯¼å‡ºæ•°æ®", "æ•´ç†æ•°æ®", "è·å–ä¿¡æ¯"
            ],
            IntentType.MONITOR: [
                "ç›‘æ§", "è·Ÿè¸ª", "è§‚å¯Ÿ", "monitor", "track", "watch",
                "æŒç»­å…³æ³¨", "å®šæœŸæ£€æŸ¥", "å®æ—¶ç›‘æ§"
            ],
            IntentType.COMPARE: [
                "å¯¹æ¯”", "æ¯”è¾ƒ", "compare", "contrast", "vs",
                "å¯¹æ¯”åˆ†æ", "æ¯”è¾ƒåˆ†æ", "ç«å“åˆ†æ"
            ]
        }
        
        # å†…å®¹ç±»å‹å…³é”®è¯
        self.content_type_keywords = {
            "news": ["æ–°é—»", "èµ„è®¯", "æ¶ˆæ¯", "news", "article"],
            "academic": ["è®ºæ–‡", "å­¦æœ¯", "ç ”ç©¶", "paper", "academic", "scholar"],
            "product": ["äº§å“", "å•†å“", "ä»·æ ¼", "product", "price", "shopping"],
            "social": ["ç¤¾äº¤", "å¾®åš", "æ¨ç‰¹", "social", "twitter", "weibo"],
            "video": ["è§†é¢‘", "å½±ç‰‡", "video", "movie", "film"],
            "image": ["å›¾ç‰‡", "ç…§ç‰‡", "å›¾åƒ", "image", "photo", "picture"]
        }
        
        # è¯­è¨€åå¥½å…³é”®è¯
        self.language_keywords = {
            "chinese": ["ä¸­æ–‡", "ä¸­å›½", "å›½å†…", "chinese", "china"],
            "english": ["è‹±æ–‡", "è‹±è¯­", "å›½å¤–", "english", "international"],
            "japanese": ["æ—¥æ–‡", "æ—¥è¯­", "æ—¥æœ¬", "japanese", "japan"],
            "korean": ["éŸ©æ–‡", "éŸ©è¯­", "éŸ©å›½", "korean", "korea"]
        }
    
    def analyze(self, user_input: str) -> UserIntent:
        """åˆ†æç”¨æˆ·æ„å›¾"""
        # é¢„å¤„ç†è¾“å…¥
        processed_input = user_input.lower().strip()
        tokens = self._tokenize(processed_input)
        
        # åˆ†ææœç´¢å¼•æ“æ„å›¾ (æœ€é«˜ä¼˜å…ˆçº§)
        search_engine, engine_intent = self._analyze_search_engine_intent(user_input)
        
        # åˆ†æä¸»è¦æ„å›¾
        primary_intent, confidence = self._analyze_primary_intent(processed_input)
        
        # åˆ†æå†…å®¹ç±»å‹
        content_type = self._analyze_content_type(processed_input)
        
        # åˆ†æè¯­è¨€åå¥½
        language_preference = self._analyze_language_preference(processed_input)
        
        # åˆ†æç‰¹æ®Šéœ€æ±‚
        special_needs = self._analyze_special_needs(processed_input)
        
        # æå–æœç´¢å…³é”®è¯
        search_keywords = self._extract_search_keywords(user_input, search_engine)
        
        return UserIntent(
            primary_intent=primary_intent,
            confidence=confidence,
            search_engine=search_engine,
            search_engine_intent=engine_intent,
            search_keywords=search_keywords,
            content_type=content_type,
            language_preference=language_preference,
            stealth_required=special_needs.get("stealth", False),
            dynamic_content=special_needs.get("dynamic", False),
            batch_processing=special_needs.get("batch", False),
            raw_input=user_input,
            processed_tokens=tokens
        )
    
    def _tokenize(self, text: str) -> List[str]:
        """åˆ†è¯å¤„ç†"""
        # ç®€å•çš„åˆ†è¯ï¼Œæ”¯æŒä¸­è‹±æ–‡
        tokens = re.findall(r'\w+', text)
        return tokens
    
    def _analyze_search_engine_intent(self, user_input: str) -> tuple[Optional[str], SearchEngineIntent]:
        """åˆ†ææœç´¢å¼•æ“æ„å›¾ - æ ¸å¿ƒåŠŸèƒ½ï¼Œå¿…é¡»å‡†ç¡®"""
        
        # æ£€æŸ¥æ˜ç¡®æŒ‡å®šçš„æœç´¢å¼•æ“
        for engine, keywords in self.search_engine_keywords.items():
            for keyword in keywords:
                if keyword in user_input:
                    # æ‰¾åˆ°æ˜ç¡®æŒ‡å®šçš„æœç´¢å¼•æ“
                    return engine, SearchEngineIntent.EXPLICIT
        
        # æ£€æŸ¥éšå«åå¥½ (åŸºäºå†…å®¹ç±»å‹) - æŒ‰ä¼˜åŒ–åçš„ä¼˜å…ˆçº§é¡ºåºæ£€æŸ¥
        
        # 1. å­¦æœ¯å†…å®¹åå¥½ - æœ€é«˜ä¼˜å…ˆçº§ï¼ŒGoogle åœ¨å­¦æœ¯æœç´¢æ–¹é¢æœ€å¼º
        academic_indicators = ["å­¦æœ¯", "è®ºæ–‡", "ç ”ç©¶", "paper", "research", "academic", "scholar", "ç§‘ç ”", "æœŸåˆŠ", "æ–‡çŒ®"]
        if any(word in user_input.lower() for word in academic_indicators):
            return "google", SearchEngineIntent.IMPLICIT
        
        # 2. éšç§ä¿æŠ¤åå¥½ - é«˜ä¼˜å…ˆçº§ï¼ŒDuckDuckGo ä¸“æ³¨éšç§
        privacy_indicators = ["éšç§", "åŒ¿å", "privacy", "anonymous", "ç§å¯†", "ä¿æŠ¤", "å®‰å…¨æœç´¢"]
        if any(word in user_input.lower() for word in privacy_indicators):
            return "duckduckgo", SearchEngineIntent.IMPLICIT
        
        # 3. æŠ€æœ¯å†…å®¹åå¥½ - é«˜ä¼˜å…ˆçº§ï¼ŒGoogle åœ¨æŠ€æœ¯æœç´¢æ–¹é¢æ›´å¼ºï¼ˆæ‰©å±•å…³é”®è¯ï¼Œæå‡ä¼˜å…ˆçº§ï¼‰
        tech_indicators = [
            "ç¼–ç¨‹", "ä»£ç ", "æŠ€æœ¯", "å¼€å‘", "programming", "coding", "development", 
            "api", "github", "æ•™ç¨‹", "tutorial", "æ¡†æ¶", "framework", "åº“", "library",
            "ç®—æ³•", "algorithm", "æ•°æ®ç»“æ„", "æœºå™¨å­¦ä¹ ", "äººå·¥æ™ºèƒ½", "AI", "è½¯ä»¶", "software",
            "python", "java", "javascript", "react", "vue", "node", "æ•°æ®åº“", "database"
        ]
        if any(word in user_input.lower() for word in tech_indicators):
            return "google", SearchEngineIntent.IMPLICIT
        
        # 4. æ˜ç¡®çš„ä¸­æ–‡åœ°åŸŸåå¥½ - ä¸­ç­‰ä¼˜å…ˆçº§ï¼Œæ›´ç²¾ç¡®åŒ¹é…ï¼ˆé¿å…è¦†ç›–æŠ€æœ¯å†…å®¹ï¼‰
        chinese_local_indicators = [
            "ä¸­å›½æ–°é—»", "å›½å†…èµ„è®¯", "æœ¬åœŸå“ç‰Œ", "å¤§é™†æ”¿ç­–", "ä¸­æ–‡å°è¯´", "å›½äº§", 
            "å†…åœ°", "ä¸­æ–‡è®ºå›", "å›½å†…ç½‘ç«™", "ä¸­å›½å…¬å¸", "å›½å†…æœåŠ¡"
        ]
        if any(phrase in user_input.lower() for phrase in chinese_local_indicators):
            return "baidu", SearchEngineIntent.IMPLICIT
        
        # 5. æ–°é—»èµ„è®¯åå¥½ - è¾ƒä½ä¼˜å…ˆçº§ï¼Œæ ¹æ®æ˜ç¡®çš„åœ°åŸŸéœ€æ±‚é€‰æ‹©
        news_indicators = ["æ–°é—»", "èµ„è®¯", "æ¶ˆæ¯", "news", "breaking", "latest"]
        if any(word in user_input.lower() for word in news_indicators):
            # åªæœ‰æ˜ç¡®æåˆ°ä¸­å›½/å›½å†…çš„æ–°é—»æ‰ç”¨ç™¾åº¦
            if any(phrase in user_input.lower() for phrase in ["ä¸­å›½æ–°é—»", "å›½å†…æ–°é—»", "å¤§é™†æ–°é—»"]):
                return "baidu", SearchEngineIntent.IMPLICIT
            else:
                return "google", SearchEngineIntent.IMPLICIT
        
        # é»˜è®¤é€‰æ‹© Googleï¼ˆå…¨çƒåŒ–è€ƒè™‘ï¼ŒæŠ€æœ¯å†…å®¹æ›´å…¨é¢ï¼‰
        return "google", SearchEngineIntent.AUTO
    
    def _analyze_primary_intent(self, processed_input: str) -> tuple[IntentType, float]:
        """åˆ†æä¸»è¦æ„å›¾"""
        intent_scores = {}
        
        for intent_type, keywords in self.intent_keywords.items():
            score = 0
            for keyword in keywords:
                if keyword in processed_input:
                    score += 1
            
            if score > 0:
                intent_scores[intent_type] = score
        
        if intent_scores:
            # æ‰¾åˆ°å¾—åˆ†æœ€é«˜çš„æ„å›¾
            primary_intent = max(intent_scores, key=intent_scores.get)
            max_score = intent_scores[primary_intent]
            total_keywords = sum(len(keywords) for keywords in self.intent_keywords.values())
            confidence = min(max_score / 3.0, 1.0)  # æ ‡å‡†åŒ–ç½®ä¿¡åº¦
            return primary_intent, confidence
        
        # é»˜è®¤ä¸ºæœç´¢æ„å›¾
        return IntentType.SEARCH, 0.5
    
    def _analyze_content_type(self, processed_input: str) -> Optional[str]:
        """åˆ†æå†…å®¹ç±»å‹"""
        for content_type, keywords in self.content_type_keywords.items():
            if any(keyword in processed_input for keyword in keywords):
                return content_type
        return None
    
    def _analyze_language_preference(self, processed_input: str) -> Optional[str]:
        """åˆ†æè¯­è¨€åå¥½"""
        for language, keywords in self.language_keywords.items():
            if any(keyword in processed_input for keyword in keywords):
                return language
        
        # åŸºäºè¾“å…¥æ–‡æœ¬çš„å­—ç¬¦åˆ¤æ–­
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', processed_input))
        total_chars = len(processed_input.replace(' ', ''))
        
        if total_chars > 0 and chinese_chars / total_chars > 0.3:
            return "chinese"
        
        return None
    
    def _analyze_special_needs(self, processed_input: str) -> Dict[str, bool]:
        """åˆ†æç‰¹æ®Šéœ€æ±‚"""
        stealth_keywords = ["éšèº«", "å·å·", "æ‚„æ‚„", "ç»•è¿‡", "é¿å¼€", "stealth", "anonymous"]
        dynamic_keywords = ["åŠ¨æ€", "å¼‚æ­¥", "ç­‰å¾…", "åŠ è½½", "dynamic", "ajax", "spa"]
        batch_keywords = ["æ‰¹é‡", "å¤šä¸ª", "ä¸€æ‰¹", "batch", "multiple", "bulk"]
        
        return {
            "stealth": any(keyword in processed_input for keyword in stealth_keywords),
            "dynamic": any(keyword in processed_input for keyword in dynamic_keywords),
            "batch": any(keyword in processed_input for keyword in batch_keywords)
        }
    
    def _extract_search_keywords(self, user_input: str, search_engine: Optional[str]) -> List[str]:
        """æå–æœç´¢å…³é”®è¯"""
        # ç§»é™¤æœç´¢å¼•æ“ç›¸å…³çš„è¯æ±‡
        cleaned_input = user_input
        
        if search_engine:
            for keyword in self.search_engine_keywords.get(search_engine, []):
                cleaned_input = cleaned_input.replace(keyword, "")
        
        # ç§»é™¤å¸¸è§çš„åŠ¨ä½œè¯
        action_words = ["æœç´¢", "æŸ¥æ‰¾", "æ‰¾", "search", "find", "ç”¨", "åœ¨", "é€šè¿‡"]
        for word in action_words:
            cleaned_input = cleaned_input.replace(word, "")
        
        # æå–å…³é”®è¯
        keywords = [word.strip() for word in cleaned_input.split() if word.strip()]
        keywords = [word for word in keywords if len(word) > 1]  # è¿‡æ»¤å•å­—ç¬¦
        
        return keywords[:5]  # é™åˆ¶å…³é”®è¯æ•°é‡
    
    def get_search_engine_recommendation(self, intent: UserIntent) -> str:
        """æ ¹æ®æ„å›¾æ¨èæœç´¢å¼•æ“ - åŸºäºå„å¼•æ“çš„å®é™…ä¼˜åŠ¿"""
        # å¦‚æœç”¨æˆ·æ˜ç¡®æŒ‡å®šï¼Œå¿…é¡»å°Šé‡
        if intent.search_engine_intent == SearchEngineIntent.EXPLICIT:
            return intent.search_engine
        
        # å¦‚æœå·²ç»æœ‰éšå«åå¥½çš„æœç´¢å¼•æ“ï¼Œç›´æ¥ä½¿ç”¨
        if intent.search_engine_intent == SearchEngineIntent.IMPLICIT and intent.search_engine:
            return intent.search_engine
        
        # åŸºäºå†…å®¹ç±»å‹å’Œè¯­è¨€åå¥½çš„ç²¾ç¡®æ¨èï¼ˆä¼˜åŒ–åçš„ä¼˜å…ˆçº§ï¼‰
        
        # å­¦æœ¯å†…å®¹ - Google æ˜¯å­¦æœ¯æœç´¢çš„é¦–é€‰
        if intent.content_type == "academic":
            return "google"
        
        # éšç§ä¿æŠ¤éœ€æ±‚ - DuckDuckGo ä¸“ä¸š
        if intent.stealth_required:
            return "duckduckgo"
        
        # æŠ€æœ¯å†…å®¹ - Google æŠ€æœ¯æœç´¢æ›´å¼ºï¼ˆæå‡ä¼˜å…ˆçº§ï¼Œä¼˜äºè¯­è¨€åå¥½ï¼‰
        if intent.content_type in ["programming", "tech", "development"]:
            return "google"
        
        # æ˜ç¡®çš„ä¸­æ–‡åœ°åŸŸå†…å®¹ - ç™¾åº¦æ›´é€‚åˆï¼ˆé™ä½ä¼˜å…ˆçº§ï¼Œæ›´ç²¾ç¡®åŒ¹é…ï¼‰
        if intent.language_preference == "chinese" and intent.content_type in ["news", "local", "culture"]:
            return "baidu"
        
        # æ–°é—»å†…å®¹ - æ ¹æ®è¯­è¨€åå¥½
        if intent.content_type == "news":
            if intent.language_preference == "chinese":
                return "baidu"
            else:
                return "google"
        
        # å•†ä¸š/äº§å“ä¿¡æ¯ - Google å•†ä¸šæœç´¢è¾ƒå…¨é¢
        if intent.content_type in ["product", "business", "commercial"]:
            return "google"
        
        # ç¤¾äº¤åª’ä½“å†…å®¹ - æ ¹æ®å¹³å°é€‰æ‹©
        if intent.content_type == "social":
            return "google"  # Google å¯¹ç¤¾äº¤åª’ä½“ç´¢å¼•è¾ƒå¥½
        
        # é»˜è®¤æ¨è - Google ä½œä¸ºç»¼åˆæ€§æœ€å¼ºçš„æœç´¢å¼•æ“
        return "google"
    
    def explain_intent(self, intent: UserIntent) -> str:
        """è§£é‡Šæ„å›¾åˆ†æç»“æœ"""
        explanation = f"ğŸ¯ æ„å›¾åˆ†æç»“æœ:\n"
        explanation += f"ä¸»è¦æ„å›¾: {intent.primary_intent.value} (ç½®ä¿¡åº¦: {intent.confidence:.2f})\n"
        
        if intent.search_engine:
            engine_type = "æ˜ç¡®æŒ‡å®š" if intent.search_engine_intent == SearchEngineIntent.EXPLICIT else "æ™ºèƒ½æ¨è"
            explanation += f"æœç´¢å¼•æ“: {intent.search_engine} ({engine_type})\n"
        
        if intent.search_keywords:
            explanation += f"æœç´¢å…³é”®è¯: {', '.join(intent.search_keywords)}\n"
        
        if intent.content_type:
            explanation += f"å†…å®¹ç±»å‹: {intent.content_type}\n"
        
        if intent.language_preference:
            explanation += f"è¯­è¨€åå¥½: {intent.language_preference}\n"
        
        special_needs = []
        if intent.stealth_required:
            special_needs.append("éšèº«æ¨¡å¼")
        if intent.dynamic_content:
            special_needs.append("åŠ¨æ€å†…å®¹")
        if intent.batch_processing:
            special_needs.append("æ‰¹é‡å¤„ç†")
        
        if special_needs:
            explanation += f"ç‰¹æ®Šéœ€æ±‚: {', '.join(special_needs)}\n"
        
        return explanation

# å…¨å±€æ„å›¾åˆ†æå™¨å®ä¾‹
intent_analyzer = V6IntentAnalyzer()

def analyze_user_intent(user_input: str) -> UserIntent:
    """åˆ†æç”¨æˆ·æ„å›¾çš„ä¾¿æ·å‡½æ•°"""
    return intent_analyzer.analyze(user_input)
