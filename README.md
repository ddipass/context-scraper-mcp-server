# Context Scraper MCP Server

ä¸€ä¸ªåŸºäº [Crawl4AI](https://github.com/unclecode/crawl4ai) çš„å¢å¼ºç‰ˆ Model Context Protocol (MCP) æœåŠ¡å™¨ï¼Œä¸º Amazon Q Developer å’Œå…¶ä»– AI å·¥å…·æä¾›å¼ºå¤§çš„ç½‘é¡µçˆ¬å–å’Œå†…å®¹æå–åŠŸèƒ½ã€‚

## ğŸš€ åŠŸèƒ½ç‰¹æ€§

### ğŸ§  æ™ºèƒ½çˆ¬å–èƒ½åŠ›
- **æ™ºèƒ½å†…å®¹è¿‡æ»¤**: è‡ªåŠ¨å»é™¤å¹¿å‘Šã€å¯¼èˆªç­‰å™ªéŸ³å†…å®¹
- **åŠ¨æ€å†…å®¹å¤„ç†**: æ”¯æŒ JavaScript æ¸²æŸ“å’Œ SPA åº”ç”¨
- **æˆªå›¾åŠŸèƒ½**: ç”Ÿæˆç½‘é¡µæˆªå›¾å¹¶è½¬æ¢ä¸º Base64 æ ¼å¼
- **å†…å®¹ç±»å‹è¯†åˆ«**: æ”¯æŒ 15+ ç§å†…å®¹ç±»å‹è‡ªåŠ¨è¯†åˆ«ä¼˜åŒ–

### ğŸ› ï¸ æ ¸å¿ƒå·¥å…· (8ä¸ª)
#### åŸºç¡€å·¥å…· (4ä¸ª)
- `crawl` - åŸºç¡€ç½‘é¡µçˆ¬å–ï¼Œè¿”å› Markdown æ ¼å¼å†…å®¹
- `crawl_with_selector` - ä½¿ç”¨ CSS é€‰æ‹©å™¨ç²¾ç¡®æå–ç‰¹å®šå†…å®¹
- `crawl_multiple` - æ‰¹é‡çˆ¬å–å¤šä¸ª URLï¼Œç”¨é€—å·åˆ†éš”
- `health_check` - æ£€æŸ¥ç½‘ç«™å¯è®¿é—®æ€§å’ŒåŸºæœ¬ä¿¡æ¯

#### å¢å¼ºå·¥å…· (4ä¸ª)
- `crawl_clean` - æ™ºèƒ½æ¸…ç†çˆ¬å–ï¼Œè‡ªåŠ¨è¿‡æ»¤å™ªéŸ³å†…å®¹
- `crawl_with_screenshot` - çˆ¬å–ç½‘é¡µå¹¶ç”Ÿæˆæˆªå›¾
- `crawl_dynamic` - åŠ¨æ€å†…å®¹çˆ¬å–ï¼Œç­‰å¾… JavaScript æ¸²æŸ“
- `crawl_smart_batch` - æ™ºèƒ½æ‰¹é‡çˆ¬å–ï¼Œæ ¹æ®å†…å®¹ç±»å‹ä¼˜åŒ–ç­–ç•¥

### ğŸ¯ æ™ºèƒ½æç¤ºç³»ç»Ÿ (9ä¸ª)
- `create_context_from_url` - æ™ºèƒ½ä¿å­˜åˆ° Amazon Q ä¸Šä¸‹æ–‡
- `research_with_sources` - åŸºäºå¤šä¸ªæ¥æºè¿›è¡Œæ·±åº¦ç ”ç©¶
- `extract_product_data` - æ™ºèƒ½æå–äº§å“ä¿¡æ¯
- `monitor_site_content` - è®¾ç½®ç½‘ç«™å†…å®¹ç›‘æ§åŸºçº¿
- `analyze_competitor_sites` - ç«äº‰å¯¹æ‰‹ç½‘ç«™åˆ†æ
- `capture_dynamic_content` - æ•è·åŠ¨æ€åŠ è½½çš„å†…å®¹
- `extract_structured_data` - æå–ç»“æ„åŒ–æ•°æ®
- `quick_site_audit` - å¿«é€Ÿç½‘ç«™ç»¼åˆå®¡è®¡
- å„ç§ä¸“ä¸šåœºæ™¯çš„å®šåˆ¶æç¤º

## ğŸ“¦ å®‰è£…

### å‰ç½®è¦æ±‚
- Python 3.12+
- uv (æ¨èï¼Œç°ä»£ Python åŒ…ç®¡ç†å™¨)

### æ–¹æ³•ä¸€ï¼šä» GitHub å…‹éš†ï¼ˆæ¨èï¼‰

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/ddipass/context-scraper-mcp-server.git
cd context-scraper-mcp-server

# ä½¿ç”¨ uv å®‰è£…ä¾èµ–
uv sync

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate

# è¿è¡Œ Crawl4AI åå®‰è£…è®¾ç½®
crawl4ai-setup
```

### æ–¹æ³•äºŒï¼šä»é›¶å¼€å§‹åˆ›å»º

å¦‚æœä½ æƒ³ä»å¤´å¼€å§‹åˆ›å»ºé¡¹ç›®ï¼š

```bash
# åˆå§‹åŒ–é¡¹ç›®
uv init context-scraper-mcp-server
cd context-scraper-mcp-server

# å®‰è£…ä¾èµ–
uv add "mcp[cli]" crawl4ai

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate

# è¿è¡Œ Crawl4AI åå®‰è£…è®¾ç½®
crawl4ai-setup
```

### æ–¹æ³•ä¸‰ï¼šä½¿ç”¨ä¼ ç»Ÿ pip

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/ddipass/context-scraper-mcp-server.git
cd context-scraper-mcp-server

# å®‰è£…ä¾èµ–
pip install -e .

# å®‰è£…æµè§ˆå™¨ä¾èµ–
python -m playwright install chromium

# è¿è¡Œ Crawl4AI è®¾ç½®
crawl4ai-setup
```

### å…³äº uv

æˆ‘ä»¬æ¨èä½¿ç”¨ [uv](https://github.com/astral-sh/uv) - è¿™æ˜¯ä¸€ä¸ªç”¨ Rust æ„å»ºçš„ç°ä»£ Python åŒ…ç®¡ç†å™¨ï¼Œå®ƒï¼š
- æ¯”ä¼ ç»Ÿçš„ pip å¿«å¾—å¤š
- æ˜¯ Python MCP SDK æ¨èçš„æ ‡å‡†å·¥å…·
- æä¾›æ›´å¥½çš„ä¾èµ–ç®¡ç†å’Œè™šæ‹Ÿç¯å¢ƒå¤„ç†

## ğŸ› ï¸ ä½¿ç”¨æ–¹æ³•

### å¯åŠ¨æœåŠ¡å™¨

```bash
# ä½¿ç”¨ uv (æ¨è)
uv run --with mcp mcp run server.py

# æˆ–ä½¿ç”¨ pip
python -m mcp run server.py
```

### åœ¨ Amazon Q Developer ä¸­é…ç½®

å°†ä»¥ä¸‹é…ç½®æ·»åŠ åˆ°ä½ çš„ MCP å®¢æˆ·ç«¯é…ç½®ä¸­ï¼š

#### æ–¹æ³•ä¸€ï¼šåˆ›å»º MCP é…ç½®æ–‡ä»¶

åœ¨ `.amazonq` ç›®å½•ä¸­åˆ›å»º `mcp.json` æ–‡ä»¶ï¼š

```json
{
    "mcpServers": {
        "ContextScraper": {
            "command": "uv",
            "args": ["run", "--with", "mcp", "mcp", "run", "server.py"],
            "cwd": "/path/to/context-scraper-mcp-server"
        }
    }
}
```

#### æ–¹æ³•äºŒï¼šç›´æ¥é…ç½®ï¼ˆå¦‚æœä½¿ç”¨å…¶ä»– MCP å®¢æˆ·ç«¯ï¼‰

```json
{
  "mcpServers": {
    "context-scraper": {
      "command": "uv",
      "args": ["run", "--with", "mcp", "mcp", "run", "server.py"],
      "cwd": "/path/to/context-scraper-mcp-server"
    }
  }
}
```

### éªŒè¯å®‰è£…

å¯åŠ¨æœåŠ¡å™¨åï¼Œä½ åº”è¯¥èƒ½çœ‹åˆ°ç±»ä¼¼ä»¥ä¸‹çš„è¾“å‡ºï¼š
```
MCP Server running on stdio
```

## ğŸ® æœåŠ¡å™¨ç®¡ç†

é¡¹ç›®æä¾›äº†ä¾¿æ·çš„æœåŠ¡å™¨ç®¡ç†å·¥å…·ï¼š

```bash
# æŸ¥çœ‹æœåŠ¡å™¨çŠ¶æ€
python manage_server.py status

# åœæ­¢æœåŠ¡å™¨
python manage_server.py stop

# å¯åŠ¨æœåŠ¡å™¨
python manage_server.py start

# é‡å¯æœåŠ¡å™¨
python manage_server.py restart
```

è¯¦ç»†ç®¡ç†æŒ‡å—è¯·å‚è€ƒ [SERVER_MANAGEMENT_GUIDE.md](./SERVER_MANAGEMENT_GUIDE.md)

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### æ™ºèƒ½çˆ¬å–ï¼ˆæ¨èï¼‰
è®© Amazon Q æ ¹æ®ä½ çš„æè¿°è‡ªåŠ¨é€‰æ‹©æœ€ä½³å·¥å…·ï¼š

```
"å¸®æˆ‘çˆ¬å–è¿™ä¸ªå•†å“é¡µé¢çš„ä»·æ ¼ä¿¡æ¯"
"è·å–è¿™å‡ ä¸ªæ–°é—»ç½‘ç«™çš„æ–‡ç« å†…å®¹ï¼Œéœ€è¦å¹²å‡€çš„æ ¼å¼"
"åˆ†æè¿™ä¸ªç«äº‰å¯¹æ‰‹çš„äº§å“ç­–ç•¥"
"è¿™ä¸ªç½‘ç«™æ˜¯åŠ¨æ€åŠ è½½çš„ï¼Œå¸®æˆ‘å¤„ç†ä¸€ä¸‹"
```

### ç›´æ¥è°ƒç”¨å·¥å…·

#### åŸºç¡€çˆ¬å–
```python
# åŸºç¡€ç½‘é¡µçˆ¬å–
result = await crawl("https://example.com")

# CSS é€‰æ‹©å™¨æå–
result = await crawl_with_selector("https://example.com", "article, .content")

# æ‰¹é‡å¤„ç†
result = await crawl_multiple("https://site1.com,https://site2.com,https://site3.com")
```

#### å¢å¼ºåŠŸèƒ½
```python
# æ™ºèƒ½å†…å®¹è¿‡æ»¤
result = await crawl_clean("https://news-site.com/article")

# åŠ¨æ€å†…å®¹å¤„ç†
result = await crawl_dynamic("https://spa-app.com", wait_time=5)

# æ™ºèƒ½æ‰¹é‡å¤„ç†
result = await crawl_smart_batch("https://shop1.com,https://shop2.com", content_type="product")

# æˆªå›¾åŠŸèƒ½
result = await crawl_with_screenshot("https://example.com")
```

## ğŸ§  æ™ºèƒ½ç‰¹æ€§

### å†…å®¹ç±»å‹è¯†åˆ«
æ”¯æŒè‡ªåŠ¨è¯†åˆ«å’Œä¼˜åŒ–å¤„ç†ä»¥ä¸‹å†…å®¹ç±»å‹ï¼š
- `article` - æ–‡ç« å†…å®¹
- `product` - äº§å“ä¿¡æ¯
- `news` - æ–°é—»å†…å®¹
- `blog` - åšå®¢æ–‡ç« 
- `contact` - è”ç³»ä¿¡æ¯
- `pricing` - ä»·æ ¼ä¿¡æ¯
- `navigation` - å¯¼èˆªç»“æ„
- `form` - è¡¨å•å†…å®¹
- `table` - è¡¨æ ¼æ•°æ®
- ç­‰ 15+ ç§ç±»å‹

### æ™ºèƒ½é€‰æ‹©å™¨æ˜ å°„
æ¯ç§å†…å®¹ç±»å‹éƒ½æœ‰ä¼˜åŒ–çš„ CSS é€‰æ‹©å™¨ï¼š
```css
article: "article, .article, .post, .entry, .content, main, [role='main']"
product: ".product, .item, [data-product], .product-card, .product-info"
news: ".news, .article, .story, .post, [data-article], .news-item"
```

## ğŸ¯ é€‚ç”¨åœºæ™¯

### ç ”ç©¶äººå‘˜
- å­¦æœ¯è®ºæ–‡å’Œèµ„æ–™æ”¶é›†
- å¤šæºä¿¡æ¯å¯¹æ¯”åˆ†æ
- ç»“æ„åŒ–æ•°æ®æå–

### å•†ä¸šåˆ†æå¸ˆ
- å¸‚åœºè°ƒç ”å’Œè¶‹åŠ¿åˆ†æ
- ç«äº‰å¯¹æ‰‹ç›‘æ§
- äº§å“ä¿¡æ¯æ”¶é›†

### å¼€å‘è€…
- API æ•°æ®æºæ„å»º
- å†…å®¹èšåˆæœåŠ¡
- è‡ªåŠ¨åŒ–æ•°æ®æ”¶é›†

### å†…å®¹åˆ›ä½œè€…
- ç´ ææ”¶é›†å’Œæ•´ç†
- è¶‹åŠ¿ç›‘æ§
- çµæ„Ÿæ¥æºæŒ–æ˜

## ğŸ† æŠ€æœ¯ä¼˜åŠ¿

- **å®Œå…¨å…è´¹**: æ— éœ€ä»»ä½•å¤–éƒ¨ API å¯†é’¥
- **æ™ºèƒ½ä¼˜åŒ–**: æ ¹æ®å†…å®¹ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€ä½³ç­–ç•¥
- **é«˜æ€§èƒ½**: åŸºäº Crawl4AI v0.6.3 æœ€æ–°ä¼˜åŒ–
- **æ˜“äºä½¿ç”¨**: è‡ªç„¶è¯­è¨€æè¿°ï¼ŒAI è‡ªåŠ¨é€‰æ‹©å·¥å…·
- **æ¨¡å—åŒ–è®¾è®¡**: ä»£ç æ¸…æ™°ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•

## ğŸ“š æ–‡æ¡£

- [ä½¿ç”¨æŒ‡å—](./USAGE_GUIDE.md) - è¯¦ç»†çš„åŠŸèƒ½ä½¿ç”¨è¯´æ˜
- [æœåŠ¡å™¨ç®¡ç†æŒ‡å—](./SERVER_MANAGEMENT_GUIDE.md) - æœåŠ¡å™¨ç®¡ç†å’Œæ•…éšœæ’é™¤

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚

## ğŸ™ è‡´è°¢

- [Crawl4AI](https://github.com/unclecode/crawl4ai) - å¼ºå¤§çš„ç½‘é¡µçˆ¬å–åº“
- [FastMCP](https://github.com/jlowin/fastmcp) - ç®€åŒ–çš„ MCP æœåŠ¡å™¨æ¡†æ¶

## ğŸ“š ç›¸å…³é“¾æ¥

- [Crawl4AI æ–‡æ¡£](https://docs.crawl4ai.com/)
- [Model Context Protocol](https://modelcontextprotocol.io/)
- [Amazon Q Developer](https://aws.amazon.com/q/developer/)
