# Context Scraper MCP Server

ä¸€ä¸ªåŸºäº [Crawl4AI](https://github.com/unclecode/crawl4ai) çš„ Model Context Protocol (MCP) æœåŠ¡å™¨ï¼Œä¸º Amazon Q Developer å’Œå…¶ä»– AI å·¥å…·æä¾›å¼ºå¤§çš„ç½‘é¡µçˆ¬å–ã€å­¦æœ¯æœç´¢å’Œæ™ºèƒ½ç ”ç©¶åŠŸèƒ½ã€‚

## ğŸš€ æ ¸å¿ƒç‰¹æ€§

- **æ™ºèƒ½ç½‘é¡µçˆ¬å–**: æ”¯æŒåŸºç¡€ã€éšèº«ã€åœ°ç†ä½ç½®ä¼ªè£…ç­‰å¤šç§çˆ¬å–æ¨¡å¼
- **å­¦æœ¯æœç´¢å¼•æ“**: é›†æˆ Google Scholarã€arXivã€PubMed ç­‰å­¦æœ¯æ•°æ®åº“
- **æ™ºèƒ½é…ç½®ç®¡ç†**: çµæ´»çš„é…ç½®ç³»ç»Ÿï¼Œæ”¯æŒè¿è¡Œæ—¶è°ƒæ•´
- **å®éªŒæ€§AIåˆ†æ**: å¯é€‰çš„Claude APIé›†æˆç”¨äºé«˜çº§å†…å®¹åˆ†æ

## ğŸ“¦ å®‰è£…

### å‰ç½®è¦æ±‚
- Python 3.12+
- uv (æ¨è) æˆ– pip

### æ–¹æ³•ä¸€ï¼šä½¿ç”¨ uv (æ¨è)

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/ddipass/context-scraper-mcp-server.git
cd context-scraper-mcp-server

# 2. ä½¿ç”¨ uv åŒæ­¥ä¾èµ–
uv sync

# 3. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate

# 4. è¿è¡Œ Crawl4AI è®¾ç½®
crawl4ai-setup
```

### æ–¹æ³•äºŒï¼šä½¿ç”¨ä¼ ç»Ÿ pip

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/ddipass/context-scraper-mcp-server.git
cd context-scraper-mcp-server

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
# æˆ– .venv\Scripts\activate  # Windows

# 3. å®‰è£…é¡¹ç›®ä¾èµ–
pip install -e .

# 4. å®‰è£…æµè§ˆå™¨ä¾èµ–
python -m playwright install chromium

# 5. è¿è¡Œ Crawl4AI è®¾ç½®
crawl4ai-setup
```

### å…³äº uv

æˆ‘ä»¬æ¨èä½¿ç”¨ [uv](https://github.com/astral-sh/uv) - è¿™æ˜¯ä¸€ä¸ªç”¨ Rust æ„å»ºçš„ç°ä»£ Python åŒ…ç®¡ç†å™¨ï¼š

- âš¡ **é€Ÿåº¦å¿«**: æ¯”ä¼ ç»Ÿ pip å¿« 10-100 å€
- ğŸ›¡ï¸ **å¯é æ€§**: æ›´å¥½çš„ä¾èµ–è§£æå’Œå†²çªæ£€æµ‹
- ğŸ¯ **MCP å®˜æ–¹æ¨è**: Python MCP SDK æ¨èçš„æ ‡å‡†å·¥å…·

å®‰è£… uv:
```bash
# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"

# æˆ–ä½¿ç”¨ pip
pip install uv
```

## ğŸ”§ MCP é…ç½®

### Amazon Q Developer é…ç½®

åœ¨ `~/.aws/amazonq/mcp.json` æ–‡ä»¶ä¸­æ·»åŠ ä»¥ä¸‹é…ç½®ï¼š

```json
{
  "mcpServers": {
    "ContextScraper": {
      "command": "/absolute/path/to/context-scraper-mcp-server/.venv/bin/mcp",
      "args": [
        "run",
        "/absolute/path/to/context-scraper-mcp-server/server_v9.py"
      ],
      "cwd": "/absolute/path/to/context-scraper-mcp-server"
    }
  }
}
```

**é‡è¦**: è¯·å°† `/absolute/path/to/context-scraper-mcp-server` æ›¿æ¢ä¸ºä½ çš„å®é™…é¡¹ç›®è·¯å¾„ã€‚

### è·å–é¡¹ç›®ç»å¯¹è·¯å¾„

```bash
cd context-scraper-mcp-server
pwd
# å°†è¾“å‡ºçš„è·¯å¾„å¤åˆ¶åˆ°é…ç½®æ–‡ä»¶ä¸­
```

### éªŒè¯é…ç½®

å¯åŠ¨ Amazon Q Developer åï¼Œä½ åº”è¯¥èƒ½çœ‹åˆ° ContextScraper å·¥å…·å¯ç”¨ã€‚å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æµ‹è¯•ï¼š

```
ä½¿ç”¨ system_status å·¥å…·æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€
```

## ğŸ› ï¸ ä¸»è¦å·¥å…·

### ğŸ“ å­¦æœ¯æœç´¢å·¥å…·
- `academic_search` - å¤šæ•°æ®æºå­¦æœ¯æœç´¢ (Google Scholar, arXiv, PubMed)

### ğŸ•·ï¸ ç½‘é¡µçˆ¬å–å·¥å…·
- `crawl` - åŸºç¡€ç½‘é¡µçˆ¬å–
- `crawl_stealth` - éšèº«æ¨¡å¼çˆ¬å–
- `crawl_with_geolocation` - åœ°ç†ä½ç½®ä¼ªè£…çˆ¬å–
- `crawl_with_retry` - é‡è¯•æœºåˆ¶çˆ¬å–
- `crawl_with_intelligence` - æ™ºèƒ½çˆ¬å–æ¨¡å¼

### âš™ï¸ é…ç½®ç®¡ç†å·¥å…·
- `configure_crawl_settings` - çˆ¬å–å‚æ•°é…ç½®
- `quick_config_content_limit` - å¿«é€Ÿè®¾ç½®å†…å®¹æ˜¾ç¤ºé™åˆ¶
- `quick_config_word_threshold` - å¿«é€Ÿè®¾ç½®è¯æ•°é˜ˆå€¼
- `system_status` - ç³»ç»ŸçŠ¶æ€ç›‘æ§

### ğŸ”¬ å®éªŒæ€§å·¥å…·
- `experimental_claude_analysis` - Claude AI å†…å®¹åˆ†æ (éœ€è¦APIé…ç½®)

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### å­¦æœ¯æœç´¢
```python
# åœ¨ arXiv æœç´¢æœºå™¨å­¦ä¹ è®ºæ–‡
result = await academic_search("machine learning transformers", "arxiv")

# åœ¨ PubMed æœç´¢åŒ»å­¦æ–‡çŒ®
result = await academic_search("COVID-19 vaccine effectiveness", "pubmed")

# åœ¨ Google Scholar æœç´¢
result = await academic_search("climate change", "google_scholar")
```

### ç½‘é¡µçˆ¬å–
```python
# åŸºç¡€çˆ¬å–
result = await crawl("https://example.com")

# éšèº«æ¨¡å¼çˆ¬å–
result = await crawl_stealth("https://protected-site.com")

# æ™ºèƒ½çˆ¬å–
result = await crawl_with_intelligence("https://news-site.com", "smart")

# åœ°ç†ä½ç½®ä¼ªè£…çˆ¬å–
result = await crawl_with_geolocation("https://geo-restricted.com", "newyork")

# é‡è¯•æœºåˆ¶çˆ¬å–
result = await crawl_with_retry("https://unstable-site.com", max_retries=3)
```

### é…ç½®ç®¡ç†
```python
# å¿«é€Ÿè®¾ç½®å†…å®¹æ˜¾ç¤ºé™åˆ¶
result = await quick_config_content_limit(5000)

# å¿«é€Ÿè®¾ç½®è¯æ•°é˜ˆå€¼
result = await quick_config_word_threshold(100)

# æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
result = await system_status()

# é…ç½®çˆ¬å–å‚æ•°
result = await configure_crawl_settings("update", "content_limits", markdown_display_limit=8000)
```

### å®éªŒæ€§åŠŸèƒ½
```python
# Claude AI å†…å®¹åˆ†æ (éœ€è¦é…ç½®API)
result = await experimental_claude_analysis("åˆ†æè¿™æ®µæ–‡æœ¬çš„ä¸»è¦è§‚ç‚¹", "general", enable_claude=True)
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
context-scraper-mcp-server/
â”œâ”€â”€ server_v9.py              # ğŸš€ ä¸»æœåŠ¡å™¨æ–‡ä»¶ (å½“å‰ç‰ˆæœ¬)
â”œâ”€â”€ server_v8.py              # V8 ç‰ˆæœ¬æœåŠ¡å™¨
â”œâ”€â”€ server_v7.py              # V7 ç‰ˆæœ¬æœåŠ¡å™¨
â”œâ”€â”€ v9_core/                  # ğŸ§  V9 æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ intent_analyzer.py    #   ğŸ¯ ç”¨æˆ·æ„å›¾åˆ†æå¼•æ“
â”‚   â”œâ”€â”€ crawl_config_manager.py #   âš™ï¸ çˆ¬å–é…ç½®ç®¡ç†å™¨
â”‚   â””â”€â”€ config_manager.py     #   ğŸ“‹ é€šç”¨é…ç½®ç®¡ç†å™¨
â”œâ”€â”€ v9_config/                # ğŸ“‹ V9 é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ crawl_config.json     #   ğŸ”§ çˆ¬å–å‚æ•°é…ç½®
â”œâ”€â”€ config/                   # ğŸ—‚ï¸ é€šç”¨é…ç½®ç›®å½•
â”‚   â”œâ”€â”€ claude_config_example.json # Claude API é…ç½®ç¤ºä¾‹
â”‚   â””â”€â”€ v6_config/            #   å†å²ç‰ˆæœ¬é…ç½®
â”œâ”€â”€ docs/                     # ğŸ“š æ–‡æ¡£ç›®å½•
â”‚   â”œâ”€â”€ architecture/         #   ğŸ—ï¸ æ¶æ„æ–‡æ¡£
â”‚   â”œâ”€â”€ development/          #   ğŸ”§ å¼€å‘æ–‡æ¡£
â”‚   â””â”€â”€ versions/             #   ğŸ“‹ ç‰ˆæœ¬æ–‡æ¡£
â”œâ”€â”€ legacy/                   # ğŸ“¦ å†å²ç‰ˆæœ¬å’Œå¤‡ä»½
â”œâ”€â”€ .venv/                    # ğŸ Python è™šæ‹Ÿç¯å¢ƒ
â”œâ”€â”€ pyproject.toml            # ğŸ“‹ é¡¹ç›®é…ç½®æ–‡ä»¶
â”œâ”€â”€ uv.lock                   # ğŸ”’ ä¾èµ–é”å®šæ–‡ä»¶
â””â”€â”€ README.md                 # ğŸ“– é¡¹ç›®è¯´æ˜æ–‡æ¡£
```

## ğŸ”— Server V9 ä¾èµ–å…³ç³»

### æ ¸å¿ƒä¾èµ–ç»“æ„
```
server_v9.py (ä¸»æœåŠ¡å™¨)
â”œâ”€â”€ v9_core/
â”‚   â”œâ”€â”€ intent_analyzer.py    # ç”¨æˆ·æ„å›¾åˆ†æ (ç‹¬ç«‹æ¨¡å—)
â”‚   â””â”€â”€ crawl_config_manager.py # çˆ¬å–é…ç½®ç®¡ç† (ç‹¬ç«‹æ¨¡å—)
â”œâ”€â”€ v9_config/
â”‚   â””â”€â”€ crawl_config.json     # é…ç½®æ–‡ä»¶ (JSONæ ¼å¼)
â””â”€â”€ å¤–éƒ¨ä¾èµ–
    â”œâ”€â”€ crawl4ai             # ç½‘é¡µçˆ¬å–å¼•æ“
    â”œâ”€â”€ mcp                  # Model Context Protocol
    â””â”€â”€ aiohttp              # å¼‚æ­¥HTTPå®¢æˆ·ç«¯
```

### æ¨¡å—èŒè´£
- **`server_v9.py`** - ä¸»æœåŠ¡å™¨ï¼Œé›†æˆæ‰€æœ‰V9åŠŸèƒ½ï¼Œæä¾›MCPå·¥å…·æ¥å£
- **`intent_analyzer.py`** - åˆ†æç”¨æˆ·æ„å›¾ï¼Œæ”¯æŒæœç´¢ã€çˆ¬å–ã€ç ”ç©¶ç­‰å¤šç§æ„å›¾ç±»å‹
- **`crawl_config_manager.py`** - ç®¡ç†çˆ¬å–é…ç½®ï¼Œæ”¯æŒè¿è¡Œæ—¶åŠ¨æ€è°ƒæ•´å‚æ•°
- **`crawl_config.json`** - å­˜å‚¨ç”¨æˆ·åå¥½å’Œç³»ç»Ÿé…ç½®

## ğŸš€ V9 æ ¸å¿ƒåŠŸèƒ½

### ğŸ¯ æ™ºèƒ½æ„å›¾åˆ†æ
- **å¤šæ„å›¾è¯†åˆ«**: è‡ªåŠ¨è¯†åˆ«æœç´¢ã€çˆ¬å–ã€ç ”ç©¶ã€æå–ã€ç›‘æ§ã€å¯¹æ¯”ç­‰æ„å›¾ç±»å‹
  - ç›¸å…³å‡½æ•°: `analyze_user_intent()` (v9_core/intent_analyzer.py)
- **æœç´¢å¼•æ“æ™ºèƒ½é€‰æ‹©**: æ”¯æŒæ˜ç¡®æŒ‡å®šã€éšå«åå¥½ã€è‡ªåŠ¨é€‰æ‹©ä¸‰ç§æ¨¡å¼
  - ç›¸å…³æšä¸¾: `SearchEngineIntent`, `IntentType`
- **ç½®ä¿¡åº¦è¯„ä¼°**: ä¸ºæ¯ä¸ªæ„å›¾åˆ†ææä¾›ç½®ä¿¡åº¦è¯„åˆ†
  - ç›¸å…³ç±»: `UserIntent` (åŒ…å«confidenceå­—æ®µ)

### âš™ï¸ åŠ¨æ€é…ç½®ç®¡ç†
- **è¿è¡Œæ—¶é…ç½®**: æ— éœ€é‡å¯å³å¯è°ƒæ•´çˆ¬å–å‚æ•°
  - ç›¸å…³å‡½æ•°: `configure_crawl_settings()`, `reload_crawl_config()`
- **åˆ†å±‚é…ç½®**: å†…å®¹é™åˆ¶ã€è´¨é‡æ§åˆ¶ã€æ—¶é—´æ§åˆ¶ã€ç”¨æˆ·åå¥½åˆ†ç¦»ç®¡ç†
  - ç›¸å…³å‡½æ•°: `get_crawl_config()` (v9_core/crawl_config_manager.py)
- **é…ç½®æŒä¹…åŒ–**: è‡ªåŠ¨ä¿å­˜ç”¨æˆ·é…ç½®åå¥½
  - é…ç½®æ–‡ä»¶: `v9_config/crawl_config.json`
- **å¿«é€Ÿé…ç½®å·¥å…·**: æä¾›ä¾¿æ·çš„å‚æ•°è°ƒæ•´æ¥å£
  - ç›¸å…³å‡½æ•°: `quick_config_content_limit()`, `quick_config_word_threshold()`
- **è‡ªåŠ¨è™šæ‹Ÿç¯å¢ƒ**: å¯åŠ¨æ—¶è‡ªåŠ¨æ¿€æ´»é¡¹ç›®è™šæ‹Ÿç¯å¢ƒ
  - ç›¸å…³å‡½æ•°: `activate_virtual_environment()` (server_v9.py)
- **å·¥ä½œç›®å½•ä¿®æ­£**: è‡ªåŠ¨åˆ‡æ¢åˆ°æ­£ç¡®çš„å·¥ä½œç›®å½•
  - å®ç°ä½ç½®: server_v9.py å¯åŠ¨è„šæœ¬

### ğŸ•·ï¸ å¢å¼ºçˆ¬å–èƒ½åŠ›
- **å¤šæ¨¡å¼çˆ¬å–**: åŸºç¡€ã€éšèº«ã€åœ°ç†ä½ç½®ä¼ªè£…ã€é‡è¯•æœºåˆ¶
  - ç›¸å…³å‡½æ•°: `crawl()`, `crawl_stealth()`, `crawl_with_geolocation()`, `crawl_with_retry()`
- **æ™ºèƒ½å†…å®¹å¤„ç†**: è‡ªåŠ¨è¿‡æ»¤å™ªéŸ³ã€æå–æ ¸å¿ƒå†…å®¹
  - ç›¸å…³å‡½æ•°: `crawl_with_intelligence()`
- **æ‰¹é‡å¤„ç†**: æ”¯æŒå¹¶å‘çˆ¬å–å¤šä¸ªURL
  - ç›¸å…³å‡½æ•°: `crawl_multiple()` (å¦‚æœå­˜åœ¨)

### ğŸ“ å­¦æœ¯æœç´¢é›†æˆ
- **å¤šæ•°æ®æº**: Google Scholarã€arXivã€PubMedç­‰å­¦æœ¯æ•°æ®åº“
  - ç›¸å…³å‡½æ•°: `academic_search()`
- **æ·±åº¦çˆ¬å–**: æ”¯æŒæœç´¢ç»“æœçš„æ·±åº¦å†…å®¹æå–
  - å‚æ•°: `deep_crawl_count` in `academic_search()`
- **ç»“æœä¼˜åŒ–**: æ™ºèƒ½å»é‡å’Œå†…å®¹ç»“æ„åŒ–
  - å†…ç½®äºå­¦æœ¯æœç´¢å‡½æ•°ä¸­

### ğŸ”§ å®éªŒæ€§åŠŸèƒ½
- **Claude AI åˆ†æ**: å¯é€‰çš„Claude APIé›†æˆï¼Œç”¨äºé«˜çº§å†…å®¹åˆ†æ
  - ç›¸å…³å‡½æ•°: `experimental_claude_analysis()`
- **ç³»ç»ŸçŠ¶æ€ç›‘æ§**: å®æ—¶ç›‘æ§æœåŠ¡å™¨çŠ¶æ€å’Œæ€§èƒ½
  - ç›¸å…³å‡½æ•°: `system_status()`

## âš™ï¸ é«˜çº§é…ç½®

### Claude API é…ç½® (å¯é€‰)

å¦‚æœéœ€è¦ä½¿ç”¨ Claude API åŠŸèƒ½ï¼Œå¯ä»¥é…ç½® `config/claude_config_example.json`ï¼š

```json
{
  "claude_api": {
    "api_key": "your-api-key-here",
    "base_url": "https://api.anthropic.com",
    "model": "claude-3-sonnet-20240229",
    "enabled": false,
    "timeout": 30,
    "max_tokens": 4000,
    "temperature": 0.7
  }
}
```

### çˆ¬å–é…ç½®

ç¼–è¾‘ `v9_config/crawl_config.json` æ¥è°ƒæ•´çˆ¬å–å‚æ•°ï¼š

```json
{
  "content_limits": {
    "markdown_display_limit": 3000,
    "word_count_threshold": 50
  },
  "quality_control": {
    "min_content_length": 100,
    "enable_content_filtering": true
  },
  "user_preferences": {
    "show_word_count": true,
    "show_crawl_info": true
  }
}
```

## ğŸ¯ é€‚ç”¨åœºæ™¯

- **å­¦æœ¯ç ”ç©¶**: æ–‡çŒ®æœç´¢ã€è®ºæ–‡åˆ†æã€å¼•ç”¨è¿½è¸ª
- **å¸‚åœºè°ƒç ”**: ç«äº‰åˆ†æã€è¡Œä¸šæŠ¥å‘Šã€è¶‹åŠ¿ç›‘æ§
- **æŠ€æœ¯æ–‡æ¡£**: API æ–‡æ¡£æ•´ç†ã€æŠ€æœ¯èµ„æ–™æ”¶é›†
- **å†…å®¹åˆ›ä½œ**: ç´ ææ”¶é›†ã€äº‹å®æ ¸æŸ¥ã€çµæ„Ÿå‘ç°

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ‰¾ä¸åˆ° mcp å‘½ä»¤**
   ```bash
   # ç¡®ä¿è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´»
   source .venv/bin/activate
   which mcp
   ```

2. **è·¯å¾„é…ç½®é”™è¯¯**
   ```bash
   # è·å–æ­£ç¡®çš„ç»å¯¹è·¯å¾„
   cd context-scraper-mcp-server
   pwd
   ```

3. **æƒé™é—®é¢˜**
   ```bash
   # æ£€æŸ¥æ–‡ä»¶æƒé™
   ls -la ~/.aws/amazonq/mcp.json
   chmod 644 ~/.aws/amazonq/mcp.json
   ```

### æµ‹è¯•è¿æ¥

```bash
# ç›´æ¥è¿è¡ŒæœåŠ¡å™¨æµ‹è¯•
cd context-scraper-mcp-server
source .venv/bin/activate
.venv/bin/mcp run server_v9.py
```

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚

## ğŸ™ è‡´è°¢

- [Crawl4AI](https://github.com/unclecode/crawl4ai) - å¼ºå¤§çš„ç½‘é¡µçˆ¬å–åº“
- [Model Context Protocol](https://modelcontextprotocol.io/) - AI å·¥å…·é›†æˆæ ‡å‡†

## ğŸ“š ç›¸å…³é“¾æ¥

- [Crawl4AI æ–‡æ¡£](https://docs.crawl4ai.com/)
- [Model Context Protocol](https://modelcontextprotocol.io/)
- [Amazon Q Developer](https://aws.amazon.com/q/developer/)
