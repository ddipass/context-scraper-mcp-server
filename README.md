# Context Scraper MCP Server

ä¸€ä¸ªåŸºäº [Crawl4AI](https://github.com/unclecode/crawl4ai) çš„ä¸‹ä¸€ä»£ Model Context Protocol (MCP) æœåŠ¡å™¨ï¼Œä¸º Amazon Q Developer å’Œå…¶ä»– AI å·¥å…·æä¾›å¼ºå¤§çš„ç½‘é¡µçˆ¬å–å’Œæ™ºèƒ½ç ”ç©¶åŠŸèƒ½ã€‚

## ğŸš€ V6 æ ¸å¿ƒç‰¹æ€§ (æœ€æ–°)

### ğŸ¯ ç”¨æˆ·æ„å›¾è‡³ä¸Š
- **ä¸¥æ ¼éµå¾ªç”¨æˆ·æŒ‡å®š**: å½“ç”¨æˆ·æ˜ç¡®æŒ‡å®šæœç´¢å¼•æ“æ—¶ï¼Œç³»ç»Ÿ 100% éµå¾ªï¼Œç»ä¸æ›¿æ¢
- **æ¶ˆé™¤ç³»ç»Ÿåè§**: ä¸å†æœ‰å›ºåŒ–çš„æœç´¢å¼•æ“åå¥½ï¼Œç”¨æˆ·é€‰æ‹©è‡³ä¸Š
- **æ™ºèƒ½ä½†ä¸å›ºæ‰§**: æä¾›å»ºè®®ä½†ä¸å¼ºåˆ¶æ‰§è¡Œ

### ğŸ” å¤šæœç´¢å¼•æ“ç”Ÿæ€
- **5å¤§æœç´¢å¼•æ“æ”¯æŒ**: Googleã€ç™¾åº¦ã€Bingã€Yahooã€DuckDuckGo
- **æ™ºèƒ½å¼•æ“é€‰æ‹©**: åŸºäºå†…å®¹ç±»å‹å’Œè¯­è¨€åå¥½è‡ªåŠ¨æ¨è
- **æ™ºèƒ½å›é€€æœºåˆ¶**: ä¸»å¼•æ“å¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢å¤‡ç”¨å¼•æ“
- **å®æ—¶å¥åº·æ£€æŸ¥**: ç›‘æ§æ‰€æœ‰æœç´¢å¼•æ“å¯ç”¨æ€§

### ğŸ§  æ— åè§æ„å›¾åˆ†æ
- **ç²¾ç¡®æ„å›¾è¯†åˆ«**: åŒºåˆ†æ˜ç¡®æŒ‡å®šã€éšå«åå¥½ã€è‡ªåŠ¨é€‰æ‹©
- **å¤šè¯­è¨€æ”¯æŒ**: ä¸­è‹±æ–‡å…³é”®è¯æ™ºèƒ½è¯†åˆ«
- **ç‰¹æ®Šéœ€æ±‚æ£€æµ‹**: éšèº«æ¨¡å¼ã€åŠ¨æ€å†…å®¹ã€æ‰¹é‡å¤„ç†

### âš™ï¸ ç»Ÿä¸€é…ç½®ç®¡ç†
- **åˆ†å±‚é…ç½®ç³»ç»Ÿ**: ç³»ç»Ÿé…ç½®ã€ç”¨æˆ·åå¥½ã€æœç´¢å¼•æ“é…ç½®
- **è¿è¡Œæ—¶çƒ­æ›´æ–°**: æ— éœ€é‡å¯å³å¯ä¿®æ”¹é…ç½®
- **ç”¨æˆ·åå¥½æŒä¹…åŒ–**: è‡ªåŠ¨ä¿å­˜å’Œæ¢å¤ç”¨æˆ·è®¾ç½®

## ğŸ› ï¸ å®Œæ•´å·¥å…·çŸ©é˜µ (35+ å·¥å…·)

### ğŸš€ V6 æ™ºèƒ½æœç´¢å¼•æ“ (4ä¸ªæ ¸å¿ƒå·¥å…·)
- `crawl_with_intelligence` - æ™ºèƒ½ç½‘é¡µçˆ¬å–ï¼Œæ”¯æŒæœç´¢å¼•æ“ç»“æœé¡µé¢
- `smart_research_v6` - åŸºäºæœç´¢çš„æ·±åº¦ç ”ç©¶åŠ©æ‰‹
- `configure_search_engines` - æœç´¢å¼•æ“é…ç½®ç®¡ç†
- `analyze_search_intent` - ç”¨æˆ·æ„å›¾åˆ†æå’Œè§£é‡Š
- `v6_system_status` - V6 ç³»ç»ŸçŠ¶æ€ç›‘æ§

### ğŸ” V5 åˆ†å±‚ç ”ç©¶å¼•æ“ (4ä¸ª)
- `research_anything_v5` - ä¸»åŠ›ç ”ç©¶å·¥å…·ï¼Œæ”¯æŒæ‰€æœ‰æ¨¡å¼
- `research_quick_v5` - 3-8ç§’å¿«é€Ÿç ”ç©¶
- `research_deep_v5` - 30-60ç§’æ·±åº¦åˆ†æ
- `research_competitive_v5` - ä¸“ä¸šç«äº‰åˆ†æ

### ğŸ§  åŸºç¡€çˆ¬å–å·¥å…· (8ä¸ª)
- `crawl` - åŸºç¡€ç½‘é¡µçˆ¬å–ï¼Œè¿”å› Markdown æ ¼å¼
- `crawl_clean` - æ™ºèƒ½æ¸…ç†ï¼Œè‡ªåŠ¨è¿‡æ»¤å™ªéŸ³å†…å®¹
- `crawl_dynamic` - åŠ¨æ€å†…å®¹å¤„ç†ï¼Œæ”¯æŒ JavaScript æ¸²æŸ“
- `crawl_with_selector` - CSS é€‰æ‹©å™¨ç²¾ç¡®æå–
- `crawl_multiple` - æ‰¹é‡çˆ¬å–å¤šä¸ª URL
- `crawl_smart_batch` - æ™ºèƒ½æ‰¹é‡å¤„ç†ï¼Œå†…å®¹ç±»å‹ä¼˜åŒ–
- `crawl_with_screenshot` - ç½‘é¡µæˆªå›¾ + å†…å®¹æå–
- `health_check` - ç½‘ç«™å¯è®¿é—®æ€§æ£€æŸ¥

### ğŸ¯ å¢å¼ºåŠŸèƒ½å·¥å…· (18ä¸ª)
åŒ…æ‹¬éšèº«çˆ¬å–ã€åœ°ç†ä½ç½®ä¼ªè£…ã€é‡è¯•æœºåˆ¶ã€å¹¶å‘ä¼˜åŒ–ç­‰ä¸“ä¸šåŠŸèƒ½

## ğŸ“¦ å®‰è£…

### å‰ç½®è¦æ±‚
- Python 3.12+
- uv (æ¨èï¼Œç°ä»£ Python åŒ…ç®¡ç†å™¨)

### æ–¹æ³•ä¸€ï¼šä» GitHub å…‹éš†ï¼ˆæ¨èï¼‰

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/ddipass/context-scraper-mcp-server.git
cd context-scraper-mcp-server

# ä½¿ç”¨ uv å®‰è£…ä¾èµ–
uv sync

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate

# è¿è¡Œ Crawl4AI åå®‰è£…è®¾ç½®
crawl4ai-setup
```

### æ–¹æ³•äºŒï¼šä½¿ç”¨ä¼ ç»Ÿ pip

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/ddipass/context-scraper-mcp-server.git
cd context-scraper-mcp-server

# å®‰è£…ä¾èµ–
pip install -e .

# å®‰è£…æµè§ˆå™¨ä¾èµ–
python -m playwright install chromium

# è¿è¡Œ Crawl4AI è®¾ç½®
crawl4ai-setup
```

### å…³äº uv

æˆ‘ä»¬æ¨èä½¿ç”¨ [uv](https://github.com/astral-sh/uv) - è¿™æ˜¯ä¸€ä¸ªç”¨ Rust æ„å»ºçš„ç°ä»£ Python åŒ…ç®¡ç†å™¨ï¼Œå®ƒï¼š
- æ¯”ä¼ ç»Ÿçš„ pip å¿«å¾—å¤š
- æ˜¯ Python MCP SDK æ¨èçš„æ ‡å‡†å·¥å…·
- æä¾›æ›´å¥½çš„ä¾èµ–ç®¡ç†å’Œè™šæ‹Ÿç¯å¢ƒå¤„ç†

## ğŸ› ï¸ ä½¿ç”¨æ–¹æ³•

### å¯åŠ¨æœåŠ¡å™¨

```bash
# ä½¿ç”¨ uv (æ¨è)
uv run --with mcp mcp run server.py

# æˆ–ä½¿ç”¨ pip
python -m mcp run server.py
```

### åœ¨ Amazon Q Developer ä¸­é…ç½®

å°†ä»¥ä¸‹é…ç½®æ·»åŠ åˆ°ä½ çš„ MCP å®¢æˆ·ç«¯é…ç½®ä¸­ï¼š

#### æ–¹æ³•ä¸€ï¼šåˆ›å»º MCP é…ç½®æ–‡ä»¶

åœ¨ `.amazonq` ç›®å½•ä¸­åˆ›å»º `mcp.json` æ–‡ä»¶ï¼š

```json
{
    "mcpServers": {
        "ContextScraper": {
            "command": "uv",
            "args": ["run", "--with", "mcp", "mcp", "run", "server.py"],
            "cwd": "/path/to/context-scraper-mcp-server"
        }
    }
}
```

#### æ–¹æ³•äºŒï¼šç›´æ¥é…ç½®ï¼ˆå¦‚æœä½¿ç”¨å…¶ä»– MCP å®¢æˆ·ç«¯ï¼‰

```json
{
  "mcpServers": {
    "context-scraper": {
      "command": "uv",
      "args": ["run", "--with", "mcp", "mcp", "run", "server.py"],
      "cwd": "/path/to/context-scraper-mcp-server"
    }
  }
}
```

### éªŒè¯å®‰è£…

å¯åŠ¨æœåŠ¡å™¨åï¼Œä½ åº”è¯¥èƒ½çœ‹åˆ°ç±»ä¼¼ä»¥ä¸‹çš„è¾“å‡ºï¼š
```
MCP Server running on stdio
```

## âš™ï¸ é…ç½®è¯´æ˜

### Claude API é…ç½® (å¯é€‰)

V6 æ”¯æŒ Claude 3.7 API é›†æˆï¼Œç”¨äºé«˜çº§å†…å®¹åˆ†æåŠŸèƒ½ã€‚

#### é…ç½®æ­¥éª¤

1. **ç¼–è¾‘ Claude é…ç½®æ–‡ä»¶**
   ```bash
   # ç¼–è¾‘é…ç½®æ–‡ä»¶
   nano v6_config/claude_config.json
   ```

2. **å¡«å…¥ä½ çš„ API Key**
   ```json
   {
     "claude_api": {
       "api_key": "ä½ çš„Claude API Key",
       "base_url": "http://Bedroc-Proxy-dZmq8lX6J5TY-92025060.us-west-2.elb.amazonaws.com/api/v1",
       "model": "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
       "enabled": true,
       "timeout": 30,
       "max_tokens": 4000,
       "temperature": 0.7
     }
   }
   ```

3. **é‡å¯æœåŠ¡å™¨ä½¿é…ç½®ç”Ÿæ•ˆ**
   ```bash
   python tools/manage_server.py restart
   ```

#### é…ç½®å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `api_key` | Claude API å¯†é’¥ | `""` (å¿…å¡«) |
| `base_url` | API åŸºç¡€URL | Bedrockä»£ç†åœ°å€ |
| `model` | ä½¿ç”¨çš„æ¨¡å‹ | `claude-3-7-sonnet` |
| `enabled` | æ˜¯å¦å¯ç”¨ClaudeåŠŸèƒ½ | `false` |
| `timeout` | è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’) | `30` |
| `max_tokens` | æœ€å¤§tokenæ•° | `4000` |
| `temperature` | ç”Ÿæˆæ¸©åº¦ | `0.7` |

#### å®‰å…¨æé†’
- ğŸ”’ è¯·å¦¥å–„ä¿ç®¡ API Keyï¼Œä¸è¦æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿ
- ğŸš« ä¸è¦åœ¨å…¬å…±åœºæ‰€æˆ–æ–‡æ¡£ä¸­æš´éœ² API Key
- ğŸ”„ å»ºè®®å®šæœŸæ›´æ¢ API Key

### æœç´¢å¼•æ“é…ç½®

V6 æ”¯æŒå¤šæœç´¢å¼•æ“é…ç½®ï¼Œè¯¦è§ `v6_config/search_engines.json`ï¼š

```json
{
  "google": {
    "name": "Google",
    "enabled": true,
    "priority": 1
  },
  "baidu": {
    "name": "ç™¾åº¦", 
    "enabled": true,
    "priority": 2
  }
}
```

## ğŸ® æœåŠ¡å™¨ç®¡ç†

é¡¹ç›®æä¾›äº†ä¾¿æ·çš„æœåŠ¡å™¨ç®¡ç†å·¥å…·ï¼š

```bash
# æŸ¥çœ‹æœåŠ¡å™¨çŠ¶æ€
python tools/manage_server.py status

# åœæ­¢æœåŠ¡å™¨
python tools/manage_server.py stop

# å¯åŠ¨æœåŠ¡å™¨
python tools/manage_server.py start

# é‡å¯æœåŠ¡å™¨
python tools/manage_server.py restart
```

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### ğŸš€ V6 æ™ºèƒ½æœç´¢ï¼ˆæ¨èï¼‰
ä¸¥æ ¼éµå¾ªç”¨æˆ·æŒ‡å®šçš„æœç´¢å¼•æ“ï¼Œæ¶ˆé™¤ç³»ç»Ÿåè§ï¼š

```
"ç”¨Googleæœç´¢æœ€æ–°çš„AIæ–°é—»"     â†’ ä¸¥æ ¼ä½¿ç”¨Google
"ç™¾åº¦æœç´¢Pythonæ•™ç¨‹"          â†’ ä¸¥æ ¼ä½¿ç”¨ç™¾åº¦  
"ç”¨å¿…åº”æŸ¥æ‰¾å­¦æœ¯è®ºæ–‡"          â†’ ä¸¥æ ¼ä½¿ç”¨Bing
"DuckDuckGoåŒ¿åæœç´¢éšç§ä¿æŠ¤"  â†’ ä¸¥æ ¼ä½¿ç”¨DuckDuckGo
```

### ğŸ¯ V6 æ ¸å¿ƒå·¥å…·ç›´æ¥è°ƒç”¨

#### æ™ºèƒ½æœç´¢å¼•æ“
```python
# ä½¿ç”¨crawl_with_intelligenceè¿›è¡Œæœç´¢
await crawl_with_intelligence("https://www.google.com/search?q=AIæ–°é—»")
await crawl_with_intelligence("https://www.baidu.com/s?wd=Pythonæ•™ç¨‹")

# æ™ºèƒ½ç ”ç©¶ï¼Œé€šè¿‡promptå¼•å¯¼é€‰æ‹©æœç´¢å¼•æ“
await smart_research_v6("æœºå™¨å­¦ä¹ å‘å±•", preferred_engine="google")

# æ„å›¾åˆ†æ - äº†è§£V6å¦‚ä½•ç†è§£ä½ çš„éœ€æ±‚
await analyze_search_intent("ç”¨Googleæœç´¢æœ€æ–°ç§‘æŠ€æ–°é—»")
```

#### é…ç½®ç®¡ç†
```python
# æŸ¥çœ‹æ‰€æœ‰æœç´¢å¼•æ“çŠ¶æ€
await configure_search_engines("list")

# è®¾ç½®é»˜è®¤æœç´¢å¼•æ“
await configure_search_engines("set_default", engine="baidu")

# å¥åº·æ£€æŸ¥
await configure_search_engines("health_check")
```

### ğŸ” V5 åˆ†å±‚ç ”ç©¶å¼•æ“

#### æ™ºèƒ½ç ”ç©¶å¼•æ“
```python
# è‡ªåŠ¨æ¨¡å¼ - AI é€‰æ‹©æœ€ä½³ç­–ç•¥
result = await research_anything_v5("åˆ†æç‰¹æ–¯æ‹‰è‡ªåŠ¨é©¾é©¶æŠ€æœ¯", "https://tesla.com")

# å¿«é€Ÿæ¨¡å¼ - 3-8ç§’è·å–æ ¸å¿ƒä¿¡æ¯
result = await research_quick_v5("äº†è§£å…¬å¸åŸºæœ¬æƒ…å†µ", "https://company.com")

# æ·±åº¦æ¨¡å¼ - 30-60ç§’å…¨é¢åˆ†æ
result = await research_deep_v5("å¸‚åœºç«äº‰åˆ†æ", "https://competitor1.com,https://competitor2.com")

# ç«äº‰åˆ†æ - ä¸“ä¸šå¯¹æ¯”ç ”ç©¶
result = await research_competitive_v5("äº§å“åŠŸèƒ½å¯¹æ¯”", "https://product1.com,https://product2.com")
```

### ğŸ› ï¸ åŸºç¡€çˆ¬å–å·¥å…·

#### åŸºç¡€çˆ¬å–
```python
# åŸºç¡€ç½‘é¡µçˆ¬å–
result = await crawl("https://example.com")

# CSS é€‰æ‹©å™¨æå–
result = await crawl_with_selector("https://example.com", "article, .content")

# æ‰¹é‡å¤„ç†
result = await crawl_multiple("https://site1.com,https://site2.com,https://site3.com")
```

#### å¢å¼ºåŠŸèƒ½
```python
# æ™ºèƒ½å†…å®¹è¿‡æ»¤
result = await crawl_clean("https://news-site.com/article")

# åŠ¨æ€å†…å®¹å¤„ç†
result = await crawl_dynamic("https://spa-app.com", wait_time=5)

# æ™ºèƒ½æ‰¹é‡å¤„ç†
result = await crawl_smart_batch("https://shop1.com,https://shop2.com", content_type="product")

# æˆªå›¾åŠŸèƒ½
result = await crawl_with_screenshot("https://example.com")
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
context-scraper-mcp-server/
â”œâ”€â”€ server.py                 # ğŸš€ ä¸»æœåŠ¡å™¨ (V6)
â”œâ”€â”€ v6_core/                  # ğŸ§  V6 æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ config_manager.py     #   âš™ï¸ ç»Ÿä¸€é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ intent_analyzer.py    #   ğŸ¯ æ— åè§æ„å›¾åˆ†æ
â”‚   â””â”€â”€ search_manager.py     #   ğŸ” å¤šæœç´¢å¼•æ“ç®¡ç†
â”œâ”€â”€ v6_config/                # ğŸ“‹ V6 é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ search_engines.json   #   ğŸ”§ æœç´¢å¼•æ“é…ç½®
â”‚   â”œâ”€â”€ user_preferences.json #   ğŸ‘¤ ç”¨æˆ·åå¥½è®¾ç½®
â”‚   â”œâ”€â”€ system_config.json    #   ğŸ–¥ï¸ ç³»ç»Ÿé…ç½®
â”‚   â””â”€â”€ claude_config.json    #   ğŸ¤– Claude APIé…ç½®
â”œâ”€â”€ docs/                     # ğŸ“š æ–‡æ¡£ç›®å½•
â”‚   â”œâ”€â”€ architecture/         #   ğŸ—ï¸ æ¶æ„æ–‡æ¡£
â”‚   â”œâ”€â”€ development/          #   ğŸ”§ å¼€å‘æ–‡æ¡£
â”‚   â””â”€â”€ versions/             #   ğŸ“‹ ç‰ˆæœ¬æ–‡æ¡£
â”œâ”€â”€ tools/                    # ğŸ› ï¸ ç®¡ç†å·¥å…·
â”‚   â””â”€â”€ manage_server.py      #   ğŸ® æœåŠ¡å™¨ç®¡ç†
â”œâ”€â”€ legacy/                   # ğŸ“¦ å†å²ç‰ˆæœ¬
â”‚   â”œâ”€â”€ servers/              #   ğŸ—‚ï¸ å†å²æœåŠ¡å™¨æ–‡ä»¶
â”‚   â”œâ”€â”€ tests/                #   ğŸ§ª å†å²æµ‹è¯•æ–‡ä»¶
â”‚   â””â”€â”€ configs/              #   âš™ï¸ å†å²é…ç½®æ–‡ä»¶
â””â”€â”€ README.md                 # ğŸ“– é¡¹ç›®è¯´æ˜
```

## ğŸ”— V6 ä¾èµ–å…³ç³»

### æ ¸å¿ƒä¾èµ–
```python
server.py (ä¸»æœåŠ¡å™¨)
â”œâ”€â”€ v6_core/
â”‚   â”œâ”€â”€ config_manager.py     # é…ç½®ç®¡ç† (ç‹¬ç«‹æ¨¡å—)
â”‚   â”œâ”€â”€ intent_analyzer.py    # æ„å›¾åˆ†æ (ç‹¬ç«‹æ¨¡å—)
â”‚   â””â”€â”€ search_manager.py     # æœç´¢ç®¡ç† (ä¾èµ– config_manager + intent_analyzer)
â”œâ”€â”€ v6_config/               # é…ç½®æ–‡ä»¶ (JSONæ ¼å¼)
â”‚   â”œâ”€â”€ search_engines.json  # æœç´¢å¼•æ“é…ç½®
â”‚   â”œâ”€â”€ user_preferences.json # ç”¨æˆ·åå¥½
â”‚   â”œâ”€â”€ system_config.json   # ç³»ç»Ÿé…ç½®
â”‚   â””â”€â”€ claude_config.json   # Claude APIé…ç½®
â””â”€â”€ å¤–éƒ¨ä¾èµ–
    â”œâ”€â”€ crawl4ai             # ç½‘é¡µçˆ¬å–å¼•æ“
    â”œâ”€â”€ mcp                  # Model Context Protocol
    â”œâ”€â”€ aiohttp              # å¼‚æ­¥HTTPå®¢æˆ·ç«¯
    â””â”€â”€ beautifulsoup4       # HTMLè§£æ
```

### æ¨¡å—å…³ç³»
- **`server.py`** â†’ ä¸»å…¥å£ï¼Œé›†æˆæ‰€æœ‰V6åŠŸèƒ½
- **`config_manager.py`** â†’ è¢«æ‰€æœ‰æ¨¡å—ä½¿ç”¨çš„é…ç½®ä¸­å¿ƒ
- **`intent_analyzer.py`** â†’ ç‹¬ç«‹çš„æ„å›¾åˆ†æå¼•æ“
- **`search_manager.py`** â†’ ä¾èµ–é…ç½®ç®¡ç†å™¨å’Œæ„å›¾åˆ†æå™¨
- **é…ç½®æ–‡ä»¶** â†’ æ‰€æœ‰æ¨¡å—çš„æ•°æ®æº

### ä¸å†å²ç‰ˆæœ¬çš„åŒºåˆ«
- **V6**: æ¨¡å—åŒ–è®¾è®¡ï¼Œæ¸…æ™°çš„ä¾èµ–å…³ç³»ï¼Œæ— å¾ªç¯ä¾èµ–
- **V5åŠä»¥å‰**: é€šè¿‡ç»§æ‰¿é“¾è·å¾—åŠŸèƒ½ï¼Œä¾èµ–å…³ç³»å¤æ‚

## ğŸ¯ é€‚ç”¨åœºæ™¯

### ç ”ç©¶äººå‘˜
- å­¦æœ¯è®ºæ–‡å’Œèµ„æ–™æ”¶é›†
- å¤šæºä¿¡æ¯å¯¹æ¯”åˆ†æ
- ç»“æ„åŒ–æ•°æ®æå–

### å•†ä¸šåˆ†æå¸ˆ
- å¸‚åœºè°ƒç ”å’Œè¶‹åŠ¿åˆ†æ
- ç«äº‰å¯¹æ‰‹ç›‘æ§
- äº§å“ä¿¡æ¯æ”¶é›†

### å¼€å‘è€…
- API æ•°æ®æºæ„å»º
- å†…å®¹èšåˆæœåŠ¡
- è‡ªåŠ¨åŒ–æ•°æ®æ”¶é›†

### å†…å®¹åˆ›ä½œè€…
- ç´ ææ”¶é›†å’Œæ•´ç†
- è¶‹åŠ¿ç›‘æ§
- çµæ„Ÿæ¥æºæŒ–æ˜

## ğŸ† æŠ€æœ¯ä¼˜åŠ¿

- **å®Œå…¨å…è´¹**: æ— éœ€ä»»ä½•å¤–éƒ¨ API å¯†é’¥
- **æ™ºèƒ½ä¼˜åŒ–**: æ ¹æ®å†…å®¹ç±»å‹è‡ªåŠ¨é€‰æ‹©æœ€ä½³ç­–ç•¥
- **é«˜æ€§èƒ½**: åŸºäº Crawl4AI v0.6.3 æœ€æ–°ä¼˜åŒ–
- **æ˜“äºä½¿ç”¨**: è‡ªç„¶è¯­è¨€æè¿°ï¼ŒAI è‡ªåŠ¨é€‰æ‹©å·¥å…·
- **æ¨¡å—åŒ–è®¾è®¡**: ä»£ç æ¸…æ™°ï¼Œæ˜“äºç»´æŠ¤å’Œæ‰©å±•

## ğŸ“š æ–‡æ¡£

- [V6 ä¾èµ–å…³ç³»åˆ†æ](./docs/architecture/V6_DEPENDENCY_ANALYSIS.md) - V6 æ¶æ„å’Œä¾èµ–å…³ç³»è¯¦è§£
- [V6 å‡çº§å®ŒæˆæŠ¥å‘Š](./docs/development/V6_UPGRADE_COMPLETE.md) - V6 æ–°åŠŸèƒ½å’Œå‡çº§è¯¦æƒ…
- [V6 å‡çº§è§„åˆ’](./docs/development/V6_UPGRADE_PLAN.md) - V6 å¼€å‘è§„åˆ’å’Œè®¾è®¡ç†å¿µ
- [æœç´¢å¼•æ“åˆ†æ](./docs/architecture/SEARCH_ENGINE_ANALYSIS.md) - æœç´¢å¼•æ“ä¼˜åŠ¿åˆ†æå’ŒåŒ¹é…ç­–ç•¥
- [æœç´¢å¼•æ“ä¿®å¤æ€»ç»“](./docs/development/SEARCH_ENGINE_FIX_SUMMARY.md) - æœç´¢å¼•æ“åŒ¹é…é—®é¢˜ä¿®å¤
- [V5 ä½¿ç”¨æŒ‡å—](./docs/versions/V5_USAGE_GUIDE.md) - V5 æ–°åŠŸèƒ½è¯¦ç»†è¯´æ˜
- [ä½¿ç”¨æŒ‡å—](./docs/USAGE_GUIDE.md) - è¯¦ç»†çš„åŠŸèƒ½ä½¿ç”¨è¯´æ˜
- [æœåŠ¡å™¨ç®¡ç†æŒ‡å—](./docs/SERVER_MANAGEMENT_GUIDE.md) - æœåŠ¡å™¨ç®¡ç†å’Œæ•…éšœæ’é™¤
- [ç‰ˆæœ¬æ–‡æ¡£](./docs/versions/) - å„ç‰ˆæœ¬è¯¦ç»†æ–‡æ¡£
- [ä¾å­˜å…³ç³»åˆ†æ](./docs/architecture/DEPENDENCY_ANALYSIS.md) - é¡¹ç›®æ¶æ„å’Œä¾å­˜å…³ç³»

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚

## ğŸ™ è‡´è°¢

- [Crawl4AI](https://github.com/unclecode/crawl4ai) - å¼ºå¤§çš„ç½‘é¡µçˆ¬å–åº“
- [FastMCP](https://github.com/jlowin/fastmcp) - ç®€åŒ–çš„ MCP æœåŠ¡å™¨æ¡†æ¶

## ğŸ“š ç›¸å…³é“¾æ¥

- [Crawl4AI æ–‡æ¡£](https://docs.crawl4ai.com/)
- [Model Context Protocol](https://modelcontextprotocol.io/)
- [Amazon Q Developer](https://aws.amazon.com/q/developer/)
